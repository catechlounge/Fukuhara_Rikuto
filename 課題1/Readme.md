# covertypeデータセットを使って、気候や標高などの環境条件から、森林を占める木の種類を予測する多クラス分類問題
### データ整理
covtype.dataをcsvの形にし、左からそれぞれに
Elevation,Aspect,Slope,Horizontal_Distance_To_Hydrology,Vertical_Distance_To_Hydrology,Horizontal_Distance_To_Roadways,Hillshade_9am,Hillshade_Noon,Hillshade_3pm,Horizontal_Distance_To_Fire_Points,Wilderness_Area1,Wilderness_Area2,Wilderness_Area3,Wilderness_Area4,Soil_Type1,Soil_Type2,Soil_Type3,Soil_Type4,Soil_Type5,Soil_Type6,Soil_Type7,Soil_Type8,Soil_Type9,Soil_Type10,Soil_Type11,Soil_Type12,Soil_Type13,Soil_Type14,Soil_Type15,Soil_Type16,Soil_Type17,Soil_Type18,Soil_Type19,Soil_Type20,Soil_Type21,Soil_Type22,Soil_Type23,Soil_Type24,Soil_Type25,Soil_Type26,Soil_Type27,Soil_Type28,Soil_Type29,Soil_Type30,Soil_Type31,Soil_Type32,Soil_Type33,Soil_Type34,Soil_Type35,Soil_Type36,Soil_Type37,Soil_Type38,Soil_Type39,Soil_Type40,Cover_Type  
の名前を割り当てた。そして、目的変数であるCover_Typeとそれ以外をそれぞれtrain_yとtrain_xに分けた。またその中で検証用に分けた。  

使用したモデル：決定木  
結果：平均絶対残差：0.４２２
考察：決定木モデルの精度が低かった原因は、データ品質の悪さ、データ量の不足、適切なハイパーパラメータの設定不足などが考えられる。これらの問題に対処するためには、データの前処理、データ拡張、ハイパーパラメータのチューニングなどを行うことが必要である。また、ランダムフォレストなどを利用し、比較的精度の低い決定木をバギングさせることで高い精度を出すことも解決策なのではないか。  

使用したモデル：ランダムフォレスト  
結果：平均絶対残差： 0.２１１
考察：決定木よりも精度が高くなった。決定木よりランダムフォレストの方が精度が高くなった理由としては、ランダムフォレストは、決定木を使用しバギングを行っているためである。また、気をつけたポイントとしてはランダムフォレストは過学習が起きやすいため、コード内のget_mae関数を使用し、一番正解率が高い葉の数を調査した。その結果、葉の枚数が50の時に一番正解率が高かった。  


# 問1
クロスバリデーションとテストデータによる予測：ランダムフォレストを使用した場合
適当な機械学習モデルとしてランダムフォレストを選択し、クロスバリデーションとテストデータに対する予測を行い、その結果と考察を報告します。
ランダムフォレストは、複数の決定木を組み合わせることにより、決定木の過学習を防ぎ、高い精度を発揮するモデルです。しかし、ランダムフォレストも過学習が起きやすいため、その対策として葉の数を調整しました。具体的には、葉の数を変更して複数回学習を行い、最もMAE（Mean Absolute Error）が小さくなる葉の数を探索しました。
結果として、葉の数が50のときに最もMAEが小さくなり、0.211になりました。この時点でモデルが適切なバランスで複雑さを制御していると解釈できます。したがって、このモデルは比較的高い精度でCover Typeを予測できていると言えます。

# 問2
問1では、全てのカラムを説明変数として用いていましたが、目的変数に関して相関があるもののみを使いたいので、./問2/visual_covertype.pyを使用して目的変数と説明変数の相関をヒートマップに表しました。これらを使用してディープラーニングを行いました。
また、ctganを使用して、ganでデータ数を増やしてそれを学習データとして、11層の深層ニューラルネットワークで学習してみましたが、検証の正解率がオリジナルのデータセットを使用して、学習させた方が正解率が高かったため、結局ctganは使用しませんでした。
また、説明変数をbox-cox変換を使用して正規分布に従わせました。正規分布に説明変数を従わせると、機械学習モデルのパフォーマンスが向上することが一般的に知られています。これは、多くの機械学習アルゴリズムが入力データが正規分布に従っているという前提を持っているためです。
Box-Cox変換は、正規分布に従わないデータを正規分布に近づけるための一般的な手法であり、これによりモデルの性能向上に寄与しました。しかし、Box-Cox変換は正の値のみに適用できる。負の値を持つ変数には各データ列の最小値を取得し、その絶対値に1を加えた値を計算しています。この値はその後、元のデータ全てに加算され、その結果全てのデータが正の値になるように変換されます。
この処理は、次に行われる自然対数の変換（`np.log1p`）において、対数変換が定義されていない負の値や0を避けるために必要です。`np.log1p`は`log(1 + x)`の計算を行いますが、これには0以上の値しか入力できません。従って、元のデータに負の値や0が存在する場合、そのまま対数変換を行うと数学的なエラーが生じます。
したがって、このコードでは最小値を用いて全てのデータを正の値に変換することで、そのようなエラーを避け、対数変換が無事に行えるようにしています。
結果的に、これらの前処理手法を組み合わせて11層の深層ニューラルネットワークモデルを訓練したところ、高い精度が得られました。また、学習過程においては平均絶対誤差（MAE）を用いて予測値と実際の値との誤差を測定し、モデルの性能を評価しました。
次のステップとしては、モデルの誤差をさらに減らすために、ハイパーパラメータチューニングや、より複雑なモデルの探索、さらなる特徴エンジニアリングなどを行っていきたいと考えています。
